{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merriekay/S23-CS167-Notes/blob/main/Day09_Decision_Trees_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPtUztopHw-v"
      },
      "source": [
        "# CS167: Day08\n",
        "## Decision Trees\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2023\n",
        "\n",
        "Thursday, February 23rd, 2023\n",
        "\n",
        "ðŸ“† [Course Schedule](https://docs.google.com/spreadsheets/d/e/2PACX-1vSvFV5Mz0_YZE1d5r3gQ8IMktE4cBAsJIlP30cl2GhEpSO0J-YWV62QokSDz-OcOCsEmxMuKpY0kVlR/pubhtml?gid=0&single=true) | ðŸ™‹[PollEverywhere](https://pollev.com/meredithmoore011) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~moore/cs167_s23_syllabus.html) | ðŸ“¬ [CodePost Login](https://codepost.io/login)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yg9RON4Hw-y"
      },
      "source": [
        "# Admin Stuff\n",
        "\n",
        "You should be working on:\n",
        "- [Notebook #3](https://classroom.github.com/a/2Jc4k7Pe) **Extension**: now due Tuesday 2/28 by 11:59pm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-OC-KoHw-z"
      },
      "source": [
        "# load in our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQNDEe9SHw-z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifxjI9A0Hw-3",
        "outputId": "dcca4b48-b2d6-43da-d4ec-79d8df6025e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt</th>\n",
              "      <th>bar</th>\n",
              "      <th>fri</th>\n",
              "      <th>hun</th>\n",
              "      <th>pat</th>\n",
              "      <th>price</th>\n",
              "      <th>rain</th>\n",
              "      <th>res</th>\n",
              "      <th>type</th>\n",
              "      <th>est</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Some</td>\n",
              "      <td>$$$</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>French</td>\n",
              "      <td>0-10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Full</td>\n",
              "      <td>$</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Thai</td>\n",
              "      <td>30-60</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Some</td>\n",
              "      <td>$</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Burger</td>\n",
              "      <td>0-10</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Full</td>\n",
              "      <td>$</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Thai</td>\n",
              "      <td>10-30</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Full</td>\n",
              "      <td>$$$</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>French</td>\n",
              "      <td>&gt;60</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alt  bar  fri  hun   pat price rain  res    type    est target\n",
              "0  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10    Yes\n",
              "1  Yes   No   No  Yes  Full     $   No   No    Thai  30-60     No\n",
              "2   No  Yes   No   No  Some     $   No   No  Burger   0-10    Yes\n",
              "3  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30    Yes\n",
              "4  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60     No"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "path = 'datasets/restaurant.csv'  #'/content/drive/MyDrive/CS167/Datasets/restaurant.csv'\n",
        "restaurant = pd.read_csv(path)\n",
        "\n",
        "restaurant.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQNfHOmDHw-6"
      },
      "source": [
        "# Quick Review:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dabfT2HHw-7"
      },
      "source": [
        "## What is a decision tree?\n",
        "<div>\n",
        "<img src=\"images/day05_dt_ex1.png\" width=800/>\n",
        "</div>\n",
        "\n",
        "[Decision Tree Example Slides](https://docs.google.com/presentation/d/1mQxycmE2gjC5i-Iwphpd_KAsaFxVDzJXkg_C2EBFGUQ/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvbdFZYeHw-8"
      },
      "source": [
        "## Decision Tree Example:\n",
        "<div>\n",
        "<img src=\"images/day08_dc_characters.png\" width=1000/>\n",
        "</div>\n",
        "\n",
        "|           | mask | cape | tie | ears | smokes | height | class |\n",
        "|-----------|:----:|:----:|:---:|:----:|:------:|:------:|:-----:|\n",
        "|   Batman  |   1  |   1  |  0  |   1  |    0   |   180  |  good |\n",
        "|   Robin   |   1  |   1  |  0  |   0  |    0   |   176  |  good |\n",
        "|   Alfred  |   0  |   0  |  1  |   0  |    0   |   185  |  good |\n",
        "|  Penguin  |   0  |   0  |  1  |   0  |    1   |   140  |  evil |\n",
        "|  Catwoman |   1  |   0  |  0  |   1  |    0   |   170  |  evil |\n",
        "|   Joker   |   0  |   0  |  0  |   0  |    0   |   179  |  evil |\n",
        "|  Batgirl  |   1  |   1  |  0  |   1  |    0   |   165  |   ?   |\n",
        "|  Riddler  |   1  |   0  |  0  |   0  |    0   |   182  |   ?   |\n",
        "| Your Date |   0  |   1  |  1  |   1  |    1   |   181  |   ?   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gE_NWOsHw--"
      },
      "source": [
        "## ðŸš¨ Terminology Alert ðŸš¨: `consistent` and `generalize`\n",
        "\n",
        "Is this tree __consistent__ with the training examples?\n",
        "- do all of the training examples get categorized appropriately?\n",
        "\n",
        "Will this tree __generalize__ well to new examples?\n",
        "- how well will new examples (test set) perform?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWkt34SXHw--"
      },
      "source": [
        "## Great, now how do I build (grow) a tree?\n",
        "\n",
        "One algorithm that builds a decision tree is called the __ID3 Decision Tree Learning Algorithm__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywtzgvR-Hw-_"
      },
      "source": [
        "It goes like this: \n",
        "    \n",
        "__Main ID3 Loop__:\n",
        "1. Assign A to be the _best_ decision feature for the next node.\n",
        "2. Assign A as decision feature for the node\n",
        "3. For each possible attribute of A, create a new descendant of node\n",
        "4. Sort training examples to leaf nodes\n",
        "5. If Training examples are perfectly classified, the STOP, Else, iterate over new leaf nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NafsnjegHw-_"
      },
      "source": [
        "### What does 'best' mean? How can we tell which node is *best*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWQYYLXSHw_A"
      },
      "source": [
        "## Selecting a feature: \n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_selecting_feature.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb_h39i-Hw_A"
      },
      "source": [
        "## Selecting a feature:\n",
        "__idea__: a good feature splits the examples into __subsets that are as pure as possible__ (ideally) 'all positive' or 'all negative'\n",
        "\n",
        "> patrons is a better choice--it gives more information about the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuANdY9LHw_G"
      },
      "source": [
        "## Information Gain:\n",
        "To select which feature to put at the **root** of the decision tree, we will calculate the **information gain** for each feature, and select the feature with the **largest information gain**.\n",
        "\n",
        "To calculate information gain, we need to be comfortable with a few concepts:\n",
        "- Prior Probabilities\n",
        "- Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzjGrk5oHw_G"
      },
      "source": [
        "## ðŸš¨ Terminology Alert ðŸš¨ `entropy`\n",
        "\n",
        "__Entropy__: measure of impurity/randomness\n",
        "- __high entropy__: more evenly split classes - highly unpredictable\n",
        "- __low entropy__: mostly one class - highly predictable\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_entropy.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF02K8IlHw_H"
      },
      "source": [
        "## Calculating Entropy Prior\n",
        "\n",
        "__Prior Probability__: aka the 'prior'\n",
        "- the split of the examples into the respective target values.\n",
        "- if I have 9 positive examples and 5 negative examples, my prior is:\n",
        "\n",
        "$\\langle 9/14, 5/14 \\rangle \\approx \\langle 0.64, 0.36 \\rangle$\n",
        "> the prior probabilities must sum to 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWGXB-qOHw_I"
      },
      "source": [
        "## Calculating Entropy:\n",
        "\n",
        "Calculating the entropy when prior is $\\langle P_1, ..., P_c\\rangle$\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_entropy_calc.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwP52UJ7Hw_I"
      },
      "source": [
        "- entropy of prior $\\langle 0.5, 0.5 \\rangle$ is $-0.5 \\log_{2}(0.5) -0.5 \\log_{2}(0.5)  = 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftBQ-5vFHw_I"
      },
      "source": [
        "- entropy of prior $\\langle 0.9, 0.1 \\rangle$ is $-0.9 \\log_{2}(0.9)-0.1 \\log_{2}(0.1) \\approx 0.47$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BolYvnPZHw_J"
      },
      "source": [
        "- entropy of prior $\\langle 0.64, 0.36 \\rangle$ is $-0.64 \\log_{2}(0.64)-0.36 \\log_{2}(0.36) \\approx 0.94$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKg5Rh9bHw_J"
      },
      "source": [
        "- entropy of prior $\\langle 0.25, 0.25, 0.5 \\rangle$ is $-0.25 \\log_{2}(0.25)-0.25 \\log_{2}(0.25)-0.5 \\log_{2}(0.5) \\approx 1.5 $\n",
        "\n",
        "> The maximum entropy is $\\log_{2}(k)$ where $k$ is the number of categories. It is not always bounded by 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl6uVDB_Hw_K",
        "outputId": "5844d2ce-dbaa-44d2-dce5-d9d9bbaef300"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.584962500721156"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "math.log2(3) # log base 2 of 3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivzuKAjMHw_K"
      },
      "source": [
        "## Code for Entropy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ6UMuqzHw_L",
        "outputId": "3ec81dfd-940d-4a8f-8af7-8e976e537cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log base 2 of 0.5 is -1.0\n",
            "log base 2 of 1 is 0.0\n",
            "log base 2 of 2 is 1.0\n",
            "log base 2 of 4 is 2.0\n",
            "log base 2 of 8 is 3.0\n",
            "log base 2 of 16 is 4.0\n",
            "log base 2 of 32 is 5.0\n",
            "log base 2 of 64 is 6.0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "# here's the syntax for a log(Base 2)\n",
        "for i in [.5,1,2,4,8,16,32,64]:\n",
        "    print(\"log base 2 of\", i, \"is\", math.log2(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdv3t3VGHw_L"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def entropy(percentage_list):\n",
        "    #input: percentage_list consists of float values that sum to 1.0 \n",
        "    #return: calculation of entropy for input percentages\n",
        "    result = 0\n",
        "    for percentage in percentage_list:\n",
        "        if percentage != 0:\n",
        "            result += -percentage*math.log2(percentage)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VV2vwxYHw_M",
        "outputId": "e507c519-85ff-43b7-b1e7-72a1eb2cd523"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9182958340544896"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#example of a calculation of entropy\n",
        "entropy([2/6,4/6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHVp8VtjHw_M",
        "outputId": "6f44977d-26d8-4cbf-d283-9771fc974140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.5"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([1/4, 1/4, 2/4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqMooAyDHw_N"
      },
      "source": [
        "## Calculating Information Gain: \n",
        "\n",
        "### Step 1: Entropy *Before*\n",
        "\n",
        "Start by calculating the entropy of the example __before__ picking a feature:\n",
        "- $\\langle 0.5, 0.5 \\rangle = 1$\n",
        "<div>\n",
        "<img src=\"images/day05_patrons_entropy.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO-paWxzHw_N",
        "outputId": "e8c14539-4a5f-4b3b-ee92-8088f22982c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Full</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Full</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Full</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Full</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Full</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Full</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Some</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Some</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Some</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pat target\n",
              "1   Full     No\n",
              "4   Full     No\n",
              "8   Full     No\n",
              "9   Full     No\n",
              "3   Full    Yes\n",
              "11  Full    Yes\n",
              "6   None     No\n",
              "10  None     No\n",
              "0   Some    Yes\n",
              "2   Some    Yes\n",
              "5   Some    Yes\n",
              "7   Some    Yes"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Patrons expected entropy\n",
        "restaurant[['pat', 'target']].sort_values(['pat', 'target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGnT2F1HHw_O"
      },
      "source": [
        "### Step 2: Calculate the Expected Entropy\n",
        "\n",
        "The __expected entropy__ for a feature is defined as the weighted sum of the entropies multiplied by the fraction of samples that belong to each set:\n",
        "\n",
        "Example:\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_expected_entropy.png\" width=1000/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNyFuPagHw_O"
      },
      "source": [
        "### Step 2: Calculate the Expected Entropy\n",
        "\n",
        "The **expected entropy** is the amount of entropy we expect after we split our data based on the values of a specific attribute/column in the dataset. \n",
        "\n",
        "**Expected Entropy** is calculated as the *weighted sum of the entropies of each partition of the data*.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_patrons_entropy2.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec3KzpL7Hw_O",
        "outputId": "8e9aa35b-d156-4d08-eda6-581b760906ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9182958340544896 0.0 0.0\n"
          ]
        }
      ],
      "source": [
        "#calculate entropy\n",
        "entropy_patrons_full = entropy([4/6,2/6]) # 4/6 was No; 2/6 was Yes\n",
        "entropy_patrons_none = entropy([2/2,0/2])\n",
        "entropy_patrons_some = entropy([0/4,4/4])\n",
        "print(entropy_patrons_full, entropy_patrons_none, entropy_patrons_some)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpKEYOfXHw_P",
        "outputId": "0340bacd-201a-4d95-a340-6ee4992df79d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4591479170272448"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate expected_entropy (weighted average)\n",
        "expected_entropy_patrons = 6/12*entropy_patrons_full + 2/12*entropy_patrons_none + 4/12*entropy_patrons_some\n",
        "expected_entropy_patrons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzCGyYARHw_x"
      },
      "source": [
        "## Information Gain:\n",
        "\n",
        "The __information gain__ is *difference* between the entropy before the test and the expected entropy after the test. \n",
        "\n",
        "$Gain() = Entropy(before) - Expected Entropy (after)$\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_IG_calc.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW7fQhB8Hw_y",
        "outputId": "90640efc-4f83-4ef0-ea5e-7a77e462cfdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5408520829727552"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#calculate information gain (prior entropy - expected entropy)\n",
        "information_gain_patrons = 1.0 - expected_entropy_patrons\n",
        "information_gain_patrons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkUn5W9EHw_y"
      },
      "source": [
        "# ðŸ’¬ Exercise:\n",
        "\n",
        "Calculate the __Information Gain__ for `hun` and `est`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOvVT87_Hw_y",
        "outputId": "eda8add7-9702-4de5-c4cc-004349831fd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hun</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hun target\n",
              "4    No     No\n",
              "6    No     No\n",
              "8    No     No\n",
              "10   No     No\n",
              "2    No    Yes\n",
              "1   Yes     No\n",
              "9   Yes     No\n",
              "0   Yes    Yes\n",
              "3   Yes    Yes\n",
              "5   Yes    Yes\n",
              "7   Yes    Yes\n",
              "11  Yes    Yes"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "restaurant[['hun', 'target']].sort_values(['hun','target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q79U2B4UHw_y"
      },
      "source": [
        "# Another Example:\n",
        "\n",
        "Information Gain Steps:\n",
        "1. Calculate the entropy before\n",
        "2. Calculte the expected entropy after\n",
        "3. Information Gain = Entropy Before - expected entropy after\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"images/entropy_calc.png\" width=500/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03D4q6K7Hw_z"
      },
      "source": [
        "# Decision Tree Considerations\n",
        "\n",
        "What do we do if we have numeric (even continuous-valued) features like age from teh titanic dataset or petal length from the iris dataset?\n",
        "\n",
        "- **Idea**: Decision Tree thresholds--`if age > 70`\n",
        "\n",
        "> Unfortunate Annoying thing: Scikit Learn Decision Tree doesn't work well with categorical data, all predictor variables must be numbers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRLBQ4ggHw_z"
      },
      "source": [
        "# Does Size Matter? Tree Size Discussion\n",
        "\n",
        "Both of these trees were made from just 12 examples. Is one better than the other?\n",
        "<div>\n",
        "<img src=\"images/day09_tree_size.png\" width=1000/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK46FjBgHw_z"
      },
      "source": [
        "## Tree Size:\n",
        "\n",
        "There are many different consistent trees possible. \n",
        "- Which qualities are preferable? more nodes v fewer nodes\n",
        "- What are the consequences of having a deep tree with many nodes? \n",
        "\n",
        "<div>\n",
        "<img src=\"images/bias_variance_tradeoff.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYU2cw7CHw_0"
      },
      "source": [
        "## Inductive Bias of ID3\n",
        "\n",
        "**Shorter trees are preferred in ID3**, trees with **high-information features closer to the root** are preferred.\n",
        "\n",
        "Baises allow us to learn, but you should understand what your algorithm's bias is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja0ZGfUsHw_0"
      },
      "source": [
        "## Leaf Nodes (Terminal Nodes)\n",
        "\n",
        "We don't always have to create a tree that is consistent with the training data. \n",
        "\n",
        "Maybe a leaf node that classifies a **majority** of the cases accurately will **generalize** better than a very deep tree. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMMivulyHw_0"
      },
      "source": [
        "Can we **always** make a consistent tree? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYDKFt_CHw_0"
      },
      "source": [
        "<div>\n",
        "<img src=\"images/day09_noisy_data.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ43c5PwHw_0"
      },
      "source": [
        "## Regression with Decision Trees:\n",
        "\n",
        "How might we go about doing **regression with decision trees**?\n",
        "- Will Information Gain work for *continuous target variables*?\n",
        "\n",
        "<div>\n",
        "<img src=\"images/day05_selecting_feature.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGp_fiFIHw_1"
      },
      "source": [
        "## Regression Example:\n",
        "<div>\n",
        "<img src=\"images/day09_regression.png\" width=300/>\n",
        "</div>\n",
        "If you had to make a prediction at a leaf node with these groups what would you predict? \n",
        "- can't calculate entropy without categorical values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHgEhkZoHw_1"
      },
      "source": [
        "## Example: MPG target values\n",
        "\n",
        "Which group of examples is more \"pure\"?\n",
        "- Group A: 20, 19, 17, 19, 18\n",
        "- Group B: 14, 17, 24, 7, 30\n",
        "> Hint: Is there some statistic that we've already talked about that can evaluate the purity of a group of numeric target values?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qQi5Gy5Hw_1"
      },
      "source": [
        "Standard Deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IFzYsQyHw_1"
      },
      "source": [
        "## Overfitting:\n",
        "\n",
        "**Big idea:** You **overfit** if you do well on the training set, but not so well on the testing set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr0itmmmHw_1"
      },
      "source": [
        "At what point did this tree 'overfit'?\n",
        "<div>\n",
        "<img src=\"images/day09_overfit.png\" width=600/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLOsTBWqHw_2"
      },
      "source": [
        "## Avoiding Overfitting:\n",
        "\n",
        "In general, **big trees overfit the data**. To avoid overfitting, **make the tree smaller**.\n",
        "\n",
        "Some ideas on avoiding overly complex trees:\n",
        "- stop growing when data split is not statistically significant\n",
        "- grow the full tree, the post-prune\n",
        "- use parameters like `max_depth`, and `num_leaf_nodes` to help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLanrvgNHw_2"
      },
      "source": [
        "# Decision Trees v kNN:\n",
        "What are the benefits of deicion trees compared to kNN?\n",
        "- disadvantages?\n",
        "\n",
        "When would you use one over the other?\n",
        "\n",
        "- *If one column highly predicts the target variable:*\n",
        "\n",
        "- *If lots of predictors have similar weight in the decision:*\n",
        "\n",
        "- *If you must be albe to interpret the data clearly:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFV7HGL7Hw_2"
      },
      "source": [
        "# Decision Trees v kNN:\n",
        "What are the benefits of deicion trees compared to kNN?\n",
        "- disadvantages?\n",
        "\n",
        "When would you use one over the other?\n",
        "\n",
        "- *If one column highly predicts the target variable:* **decision tree**\n",
        "\n",
        "- *If lots of predictors have similar weight in the decision:* **kNN**\n",
        "\n",
        "- *If you must be albe to interpret the data clearly:* **decision tree**"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}